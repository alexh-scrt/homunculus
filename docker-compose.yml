version: '3.8'

# Environment variables can be set in .env file
# See .env.example for all available options
#
# This unified compose file includes:
# - Core Homunculus services (Ollama, ChromaDB, Neo4j, Redis)
# - Arena services (Kafka, Zookeeper, PostgreSQL)
#
# Usage:
#   docker-compose -f docker-compose.unified.yml up -d
#   
# To run only core services:
#   docker-compose -f docker-compose.unified.yml up -d ollama chromadb neo4j redis
#
# To run with Arena services:
#   docker-compose -f docker-compose.unified.yml up -d
#
# For development with Kafka UI:
#   docker-compose -f docker-compose.unified.yml --profile dev up -d

services:
  # =============================================================================
  # CORE HOMUNCULUS SERVICES
  # =============================================================================

  # Ollama service - serves LLM models with auto model pulling
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    runtime: nvidia
    privileged: true
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_NUM_GPU=${OLLAMA_NUM_GPU:-1}
      - OLLAMA_NUM_THREADS=${OLLAMA_NUM_THREADS:-8}
    entrypoint: /bin/bash
    command:
      - -c
      - |
        # Start ollama in the background
        ollama serve &
        OLLAMA_PID=$!
        
        # Wait for ollama to be ready
        echo "Waiting for Ollama to start..."
        for i in {1..30}; do
          if ollama list > /dev/null 2>&1; then
            echo "Ollama is ready!"
            break
          fi
          echo "Waiting... ($i/30)"
          sleep 2
        done
        
        # Check if model exists, if not pull it
        if ! ollama list | grep -q "llama3.3:70b"; then
          echo "Pulling llama3.3:70b model..."
          ollama pull llama3.3:70b
          echo "Model pulled successfully!"
        else
          echo "Model llama3.3:70b already exists"
        fi
        
        echo "Ollama ready with models!"
        
        # Keep ollama running
        wait $OLLAMA_PID
    networks:
      - agent-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # ChromaDB - vector database for embeddings
  chromadb:
    image: chromadb/chroma:latest
    container_name: chromadb
    ports:
      - "${CHROMA_PORT:-8000}:8000"
    volumes:
      - chroma-data:/chroma/chroma
    environment:
      - IS_PERSISTENT=TRUE
      - PERSIST_DIRECTORY=${CHROMA_PERSIST_DIRECTORY:-/chroma/chroma}
      - ANONYMIZED_TELEMETRY=FALSE
    networks:
      - agent-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget --quiet --tries=1 --spider http://localhost:8000/api/v1/heartbeat || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Neo4j - graph database
  neo4j:
    image: neo4j:latest
    container_name: neo4j
    ports:
      - "${NEO4J_HTTP_PORT:-7474}:7474"  # HTTP
      - "${NEO4J_BOLT_PORT:-7687}:7687"  # Bolt
    volumes:
      - neo4j-data:/data
      - neo4j-logs:/logs
      - neo4j-import:/var/lib/neo4j/import
      - neo4j-plugins:/plugins
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD:-I1U5vG0k1upj7SpAi6Qc}
      - NEO4J_ACCEPT_LICENSE_AGREEMENT=yes
    networks:
      - agent-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "cypher-shell -u neo4j -p ${NEO4J_PASSWORD:-I1U5vG0k1upj7SpAi6Qc} 'RETURN 1' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Redis - caching and message broker
  redis:
    image: redis:latest
    container_name: redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --maxmemory ${REDIS_MAX_MEMORY:-512mb} --maxmemory-policy allkeys-lru --requirepass ${REDIS_PASSWORD:-ZBGPc4gQHGaQnlRJ15F9}
    networks:
      - agent-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-ZBGPc4gQHGaQnlRJ15F9}", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # =============================================================================
  # ARENA SERVICES (for multi-agent game environment)
  # =============================================================================

  # Zookeeper - Required for Kafka coordination
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    hostname: zookeeper
    container_name: arena-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_MAX_CLIENT_CNXNS: 100
    ports:
      - "2181:2181"
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-logs:/var/lib/zookeeper/log
    networks:
      - agent-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "echo ruok | nc localhost 2181 | grep imok"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Kafka - Message bus for Arena agent communication
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka
    container_name: arena-kafka
    depends_on:
      zookeeper:
        condition: service_started
    ports:
      - "9092:9092"  # External listener
      - "9093:9093"  # Internal listener
    environment:
      # Basic configuration
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      
      # Listeners configuration
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9093,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      
      # Topic configuration
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      
      # Auto create topics for development
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      
      # Log retention (7 days)
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      
      # Performance tuning
      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - agent-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9093"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # PostgreSQL - Game history and analytics storage
  postgres:
    image: postgres:15-alpine
    container_name: arena-postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-arena_db}
      POSTGRES_USER: ${POSTGRES_USER:-arena_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-arena_pass}
      
      # Performance tuning
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --locale=en_US.UTF-8"
      POSTGRES_MAX_CONNECTIONS: 100
      POSTGRES_SHARED_BUFFERS: 256MB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 1GB
      POSTGRES_MAINTENANCE_WORK_MEM: 64MB
      POSTGRES_CHECKPOINT_COMPLETION_TARGET: 0.9
      POSTGRES_WAL_BUFFERS: 16MB
      POSTGRES_DEFAULT_STATISTICS_TARGET: 100
      POSTGRES_RANDOM_PAGE_COST: 1.1
      POSTGRES_EFFECTIVE_IO_CONCURRENCY: 200
      POSTGRES_WORK_MEM: 4MB
      POSTGRES_MIN_WAL_SIZE: 1GB
      POSTGRES_MAX_WAL_SIZE: 4GB
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./scripts/arena/init_db.sql:/docker-entrypoint-initdb.d/01_init.sql:ro
    networks:
      - agent-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-arena_user} -d ${POSTGRES_DB:-arena_db}"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Kafka UI - Optional web interface for monitoring Kafka (development only)
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: arena-kafka-ui
    depends_on:
      - kafka
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: arena-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9093
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: PLAINTEXT
      DYNAMIC_CONFIG_ENABLED: 'true'
    networks:
      - agent-network
    restart: unless-stopped
    profiles:
      - dev  # Only start in development mode

# =============================================================================
# VOLUMES
# =============================================================================

volumes:
  # Core service volumes
  ollama-data:
    driver: local
  chroma-data:
    driver: local
  neo4j-data:
    driver: local
  neo4j-logs:
    driver: local
  neo4j-import:
    driver: local
  neo4j-plugins:
    driver: local
  redis-data:
    driver: local
  
  # Arena service volumes
  zookeeper-data:
    driver: local
  zookeeper-logs:
    driver: local
  kafka-data:
    driver: local
  postgres-data:
    driver: local

# =============================================================================
# NETWORKS
# =============================================================================

networks:
  agent-network:
    driver: bridge